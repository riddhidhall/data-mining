{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis notebook focuses on pre-processing and creating a baseline model to improve upon\\nPre-processing includes:\\n - Dummy encoding\\n - Imputation\\n - Removal of columns with high missing variables\\n\\nLogistic regression model applied (no optimisation)\\nAccuracy -> ___%\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This notebook contains code to do knn imputation (with a tuned neighbour value using random search) on the pre_processed\n",
    "data.\n",
    "\n",
    "THIS TOOK A VERY LONG TIME TO RUN AND RESULTS WEREN'T GREAT SO NOT WORTH RUNNING AGAIN\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from models import *\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n",
      "Testing data shape:  (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "train_data = load_app_training_data()\n",
    "test_data = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALIGNED:\n",
      "Training Features shape:  (307511, 240)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "# pre-processing (No imputation or normalisation is applied)\n",
    "train_data, test_data = encode_binary_cols(train_data, test_data)\n",
    "train_data, test_data = one_hot_encode(train_data, test_data)\n",
    "train_data, test_data = align_data(train_data, test_data)\n",
    "train_Y = get_train_labels(train_data)\n",
    "train_data, test_data = remove_days_employed_anomaly(train_data, test_data)\n",
    "train_data, test_data = remove_missing_cols(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlations(app_train, feature, n=15):\n",
    "    '''\n",
    "    Return a dataframe containing the top n features ranked by their pearson's correlations \n",
    "    (sorted by their absolute pcc score) \n",
    "    '''\n",
    "    correlations = app_train.corr()[feature]\n",
    "    correlations = abs(correlations).sort_values().tail(\n",
    "        n)  # sort by correlation value (regardless if it's positive or negative)\n",
    "    correlations = correlations.dropna()  # drop nans\n",
    "    if 'TARGET' in correlations:\n",
    "        correlations = correlations.drop(labels=[feature, 'TARGET'])  # remove corr to itself and target\n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_correlations(app_train):\n",
    "    \"\"\"\n",
    "    For each feature will save a dataframe storing all correlations with the feature and every other feature\n",
    "    \"\"\"\n",
    "    path = '../models/correlations/'\n",
    "    for feature in train_data.columns[:]:\n",
    "        correlations = app_train.corr()[feature]\n",
    "        if '/' in feature or ':' in feature:\n",
    "            # replace / and : with '' -> as they are invalid characters for filename \n",
    "            feature = feature.replace('/','')\n",
    "            feature = feature.replace(':','')\n",
    "        save_pickle(path+feature+'.pickle', correlations)\n",
    "    print(\"ALL CORRELATIONS SAVED\")\n",
    "\n",
    "def top_correlations_from_all(feature:str, n):\n",
    "    \"\"\"\n",
    "    Loads a previously saved dataframe containing feature corrleations and returns the top n correlated features\n",
    "    (excludes target)\n",
    "    \"\"\"\n",
    "    path = '../models/correlations/'\n",
    "    filename = feature\n",
    "    if '/' in filename or ':' in filename:\n",
    "            # replace / and : with '' -> as they are invalid characters for filename \n",
    "            filename = filename.replace('/','')\n",
    "            filename = filename.replace(':','')\n",
    "            \n",
    "    correlations = load_pickle(path+feature+'.pickle')\n",
    "    correlations = abs(correlations).sort_values().tail(n)  # sort by correlation value (regardless if it's positive or negative)\n",
    "    correlations = correlations.dropna()  # drop nans\n",
    "    if 'TARGET' in correlations:\n",
    "        correlations = correlations.drop(labels=[feature, 'TARGET'])  # remove corr to itself and target\n",
    "    return correlations\n",
    "    \n",
    "# save_all_correlations(train_data)\n",
    "# train_data.columns[181:][0].replace('/', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_corr_knn_imputation(feature, train, test, train_filled, test_filled,n_jobs):\n",
    "    \"\"\"\n",
    "    Applies knn imputation for a single column. Will use random search to try find the best neighbour\n",
    "    value (range 10-200). Returns a dataframes for the train and test with imputed column\n",
    "    \"\"\"\n",
    "    top_corrs = top_correlations_from_all(feature, 15).keys()\n",
    "    \n",
    "    # create training data from columns with values\n",
    "    not_null_mask = train[feature].notna()  # true if not nan = mask to get the values to train on\n",
    "    knn_train_x = train_filled[not_null_mask][top_corrs] # get all top corr cols (minus target) which have a feature value\n",
    "    knn_train_y = train_filled[not_null_mask][[feature]]\n",
    "    \n",
    "    # get the rows which require to be imputed for the features\n",
    "    knn_test_x = train_filled[train[feature].isna()][top_corrs]  # only null values\n",
    "    actual_test_x = test_filled[test[feature].isna()][top_corrs]  # only null values\n",
    "    \n",
    "    # train and predict\n",
    "    filename = feature.replace(':', '')\n",
    "    fileaname = feature.replace('/', '')\n",
    "    try:\n",
    "        neigh = load_pickle(\"../models/knn_corrs_rs_clf/\"+filename+\".pickle\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Training col:\", feature)\n",
    "    #     neigh = KNeighborsRegressor(n_neighbors=75)\n",
    "        model = KNeighborsRegressor()\n",
    "        n_neighbors = range(10,200)\n",
    "        hyperparameters = dict(n_neighbors=n_neighbors)\n",
    "        neigh = RandomizedSearchCV(model, hyperparameters, n_iter=7, cv=3, verbose=3, n_jobs=n_jobs)\n",
    "        neigh.fit(knn_train_x, knn_train_y)\n",
    "        save_pickle(\"../models/knn_corrs_rs_clf/\"+filename+\".pickle\", neigh)\n",
    "        \n",
    "    print('Best n_neigbors:', neigh.best_estimator_.get_params()['n_neighbors'])\n",
    "    knn_test_y = neigh.predict(knn_test_x)\n",
    "    # get the column to update nulls\n",
    "    train_imputed_col = train[[feature]]\n",
    "    train_imputed_col[train_imputed_col[feature].isna()] = knn_test_y\n",
    "    \n",
    "    # the train data has more unfilled cols than test, so sometimes imputation is not required\n",
    "    try:\n",
    "        actual_test_y = neigh.predict(actual_test_x)\n",
    "        # get the column to update nulls for app_test\n",
    "        test_imputed_col = test[[feature]]\n",
    "        test_imputed_col[test_imputed_col[feature].isna()] = actual_test_y\n",
    "    except ValueError:\n",
    "        test_imputed_col = test[[feature]]\n",
    "    \n",
    "    return train_imputed_col, test_imputed_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_knn(app_train, app_test, n_jobs):\n",
    "    \"\"\"\n",
    "    Applies knn imputation for all columns with missing values. KNN requires all other columns to be not null (so a \n",
    "    mean imputation is used to fill those columns in)\n",
    "    \"\"\"\n",
    "    count = 1\n",
    "    train_nan_cols = app_train.loc[:,app_train.isnull().any()]\n",
    "    test_nan_cols = app_test.loc[:,app_test.isnull().any()]\n",
    "    \n",
    "    train_full_impute = app_train.copy()\n",
    "    train_full_impute = train_full_impute.fillna(train_full_impute.mean())\n",
    "    test_full_impute = app_test.copy()\n",
    "    test_full_impute  = test_full_impute.fillna(train_full_impute.mean())\n",
    "\n",
    "    print(list(train_nan_cols))\n",
    "    for col in train_nan_cols: \n",
    "        imputed_train, imputed_test = top_corr_knn_imputation(col, app_train, app_test, train_full_impute, test_full_impute, n_jobs=n_jobs)\n",
    "        app_train[col] = imputed_train\n",
    "        app_test[col] = imputed_test\n",
    "        print(\"{} out of {} done - col: {}\".format(count, test_nan_cols.shape[1], col))\n",
    "        count += 1\n",
    "            \n",
    "    return app_train, app_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMT_ANNUITY', 'AMT_GOODS_PRICE', 'DAYS_EMPLOYED', 'OWN_CAR_AGE', 'CNT_FAM_MEMBERS', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n",
      "Best n_neigbors: 50\n",
      "1 out of 59 done - col: AMT_ANNUITY\n",
      "Best n_neigbors: 67\n",
      "2 out of 59 done - col: AMT_GOODS_PRICE\n",
      "Best n_neigbors: 93\n",
      "3 out of 59 done - col: DAYS_EMPLOYED\n",
      "Best n_neigbors: 19\n",
      "4 out of 59 done - col: OWN_CAR_AGE\n",
      "Best n_neigbors: 174\n",
      "5 out of 59 done - col: CNT_FAM_MEMBERS\n",
      "Best n_neigbors: 174\n",
      "6 out of 59 done - col: EXT_SOURCE_1\n",
      "Best n_neigbors: 115\n",
      "7 out of 59 done - col: EXT_SOURCE_2\n",
      "Best n_neigbors: 193\n",
      "8 out of 59 done - col: EXT_SOURCE_3\n",
      "Best n_neigbors: 34\n",
      "9 out of 59 done - col: APARTMENTS_AVG\n",
      "Best n_neigbors: 44\n",
      "10 out of 59 done - col: BASEMENTAREA_AVG\n",
      "Best n_neigbors: 35\n",
      "11 out of 59 done - col: YEARS_BEGINEXPLUATATION_AVG\n",
      "Best n_neigbors: 16\n",
      "12 out of 59 done - col: YEARS_BUILD_AVG\n",
      "Best n_neigbors: 26\n",
      "13 out of 59 done - col: COMMONAREA_AVG\n",
      "Best n_neigbors: 24\n",
      "14 out of 59 done - col: ELEVATORS_AVG\n",
      "Best n_neigbors: 16\n",
      "15 out of 59 done - col: ENTRANCES_AVG\n",
      "Best n_neigbors: 46\n",
      "16 out of 59 done - col: FLOORSMAX_AVG\n",
      "Best n_neigbors: 13\n",
      "17 out of 59 done - col: FLOORSMIN_AVG\n",
      "Best n_neigbors: 35\n",
      "18 out of 59 done - col: LANDAREA_AVG\n",
      "Best n_neigbors: 36\n",
      "19 out of 59 done - col: LIVINGAPARTMENTS_AVG\n",
      "Best n_neigbors: 25\n",
      "20 out of 59 done - col: LIVINGAREA_AVG\n",
      "Best n_neigbors: 20\n",
      "21 out of 59 done - col: NONLIVINGAPARTMENTS_AVG\n",
      "Best n_neigbors: 90\n",
      "22 out of 59 done - col: NONLIVINGAREA_AVG\n",
      "Best n_neigbors: 12\n",
      "23 out of 59 done - col: APARTMENTS_MODE\n",
      "Best n_neigbors: 79\n",
      "24 out of 59 done - col: BASEMENTAREA_MODE\n",
      "Best n_neigbors: 19\n",
      "25 out of 59 done - col: YEARS_BEGINEXPLUATATION_MODE\n",
      "Best n_neigbors: 27\n",
      "26 out of 59 done - col: YEARS_BUILD_MODE\n",
      "Best n_neigbors: 20\n",
      "27 out of 59 done - col: COMMONAREA_MODE\n",
      "Best n_neigbors: 18\n",
      "28 out of 59 done - col: ELEVATORS_MODE\n",
      "Best n_neigbors: 18\n",
      "29 out of 59 done - col: ENTRANCES_MODE\n",
      "Best n_neigbors: 57\n",
      "30 out of 59 done - col: FLOORSMAX_MODE\n",
      "Best n_neigbors: 25\n",
      "31 out of 59 done - col: FLOORSMIN_MODE\n",
      "Best n_neigbors: 57\n",
      "32 out of 59 done - col: LANDAREA_MODE\n",
      "Best n_neigbors: 12\n",
      "33 out of 59 done - col: LIVINGAPARTMENTS_MODE\n",
      "Best n_neigbors: 10\n",
      "34 out of 59 done - col: LIVINGAREA_MODE\n",
      "Best n_neigbors: 14\n",
      "35 out of 59 done - col: NONLIVINGAPARTMENTS_MODE\n",
      "Best n_neigbors: 10\n",
      "36 out of 59 done - col: NONLIVINGAREA_MODE\n",
      "Best n_neigbors: 19\n",
      "37 out of 59 done - col: APARTMENTS_MEDI\n",
      "Best n_neigbors: 29\n",
      "38 out of 59 done - col: BASEMENTAREA_MEDI\n",
      "Best n_neigbors: 21\n",
      "39 out of 59 done - col: YEARS_BEGINEXPLUATATION_MEDI\n",
      "Best n_neigbors: 17\n",
      "40 out of 59 done - col: YEARS_BUILD_MEDI\n",
      "Best n_neigbors: 20\n",
      "41 out of 59 done - col: COMMONAREA_MEDI\n",
      "Best n_neigbors: 19\n",
      "42 out of 59 done - col: ELEVATORS_MEDI\n",
      "Best n_neigbors: 36\n",
      "43 out of 59 done - col: ENTRANCES_MEDI\n",
      "Best n_neigbors: 29\n",
      "44 out of 59 done - col: FLOORSMAX_MEDI\n",
      "Best n_neigbors: 10\n",
      "45 out of 59 done - col: FLOORSMIN_MEDI\n",
      "Best n_neigbors: 30\n",
      "46 out of 59 done - col: LANDAREA_MEDI\n",
      "Best n_neigbors: 30\n",
      "47 out of 59 done - col: LIVINGAPARTMENTS_MEDI\n",
      "Best n_neigbors: 31\n",
      "48 out of 59 done - col: LIVINGAREA_MEDI\n",
      "Best n_neigbors: 14\n",
      "49 out of 59 done - col: NONLIVINGAPARTMENTS_MEDI\n",
      "Best n_neigbors: 17\n",
      "50 out of 59 done - col: NONLIVINGAREA_MEDI\n",
      "Best n_neigbors: 52\n",
      "51 out of 59 done - col: TOTALAREA_MODE\n",
      "Best n_neigbors: 87\n",
      "52 out of 59 done - col: OBS_30_CNT_SOCIAL_CIRCLE\n",
      "Best n_neigbors: 21\n",
      "53 out of 59 done - col: DEF_30_CNT_SOCIAL_CIRCLE\n",
      "Best n_neigbors: 47\n",
      "54 out of 59 done - col: OBS_60_CNT_SOCIAL_CIRCLE\n",
      "Best n_neigbors: 11\n",
      "55 out of 59 done - col: DEF_60_CNT_SOCIAL_CIRCLE\n",
      "Best n_neigbors: 31\n",
      "56 out of 59 done - col: DAYS_LAST_PHONE_CHANGE\n",
      "Best n_neigbors: 33\n",
      "57 out of 59 done - col: AMT_REQ_CREDIT_BUREAU_HOUR\n",
      "Best n_neigbors: 11\n",
      "58 out of 59 done - col: AMT_REQ_CREDIT_BUREAU_DAY\n",
      "Best n_neigbors: 24\n",
      "59 out of 59 done - col: AMT_REQ_CREDIT_BUREAU_WEEK\n",
      "Best n_neigbors: 11\n",
      "60 out of 59 done - col: AMT_REQ_CREDIT_BUREAU_MON\n",
      "Best n_neigbors: 31\n",
      "61 out of 59 done - col: AMT_REQ_CREDIT_BUREAU_QRT\n",
      "Best n_neigbors: 113\n",
      "62 out of 59 done - col: AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "File saved at  ../models/knn_impute_train_df1.pickle\n",
      "File saved at  ../models/knn_impute_test_df1.pickle\n",
      "ALIGNED:\n",
      "Training Features shape:  (307511, 241)\n",
      "Testing Features shape:  (48744, 240)\n",
      "File saved at  ../models/log_reg_new.pickle\n",
      "Log reg baseline model saved to:  ../models/knn_imputation_top_corr_log_reg1.pickle\n",
      "Predictions saved to:  ../test_predictions/knn_imputation_top_corr_log_reg1.csv\n"
     ]
    }
   ],
   "source": [
    "def log_reg_knn_imputation( app_train, app_test, model_save_path, predications_save_path, n_jobs):\n",
    "    \"\"\"\n",
    "    Impute on all columns via knn then create predictions using log reg without any tuning on C\n",
    "    \"\"\"\n",
    "    train, test = impute_knn(app_train, app_test, n_jobs=n_jobs)\n",
    "#     save_pickle(\"../models/knn_impute_train_df1.pickle\", train)\n",
    "#     save_pickle(\"../models/knn_impute_test_df1.pickle\", test)\n",
    "    train = load_pickle(\"../models/knn_impute_train_df.pickle\")\n",
    "    test = load_pickle(\"../models/knn_impute_test_df.pickle\")\n",
    "    train_Y = train['TARGET']\n",
    "\n",
    "    train = train.drop(columns=train.loc[:,train.isnull().any()].columns)  #\n",
    "    trian, test, train_Y = align_data(train,test)\n",
    "    # Drop the target and sk_id_curr from the training data\n",
    "    if 'TARGET' in train:\n",
    "        train = train.drop(columns=['TARGET'])\n",
    "    train = train.drop(columns=['SK_ID_CURR'])  #\n",
    "    test = test.drop(columns=['SK_ID_CURR'])  #\n",
    "    \n",
    "    model, preds = baseline_log_reg(train, train_Y, test, save_path=model_save_path)\n",
    "    create_and_save_submission(test_data, preds, save_path=predications_save_path)\n",
    "\n",
    "    \n",
    "log_reg_knn_imputation(train_data.copy(), test_data.copy(),\n",
    "                       model_save_path=\"../models/knn_imputation_top_corr_log_reg1.pickle\",\n",
    "                       predications_save_path='../test_predictions/knn_imputation_top_corr_log_reg1.csv',\n",
    "                       n_jobs=10) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
