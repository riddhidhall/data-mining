{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This notebook focuses on pre-processing and creating a baseline model to improve upon\n",
    "Pre-processing includes:\n",
    " - Dummy encoding\n",
    " - Imputation\n",
    " - Removal of columns with high missing variables\n",
    "\n",
    "Logistic regression model applied (no optimisation)\n",
    "Accuracy -> ___%\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, Imputer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import interp\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(path, data):\n",
    "    # pickles the tokens dict\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(\"File saved at \", path)\n",
    "\n",
    "\n",
    "def load_pickle(path):\n",
    "    # loads the tokens dict from directory\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    print(\"File loaded: \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (307511, 122)\n",
      "Testing data shape:  (48744, 121)\n"
     ]
    }
   ],
   "source": [
    "def load_training_data():\n",
    "    app_train = pd.read_csv('../input/application_train.csv')\n",
    "    print('Training data shape: ', app_train.shape)\n",
    "    return app_train\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    # Testing data features\n",
    "    app_test = pd.read_csv('../input/application_test.csv')\n",
    "    print('Testing data shape: ', app_test.shape)\n",
    "    return app_test\n",
    "\n",
    "train_data = load_training_data()\n",
    "test_data = load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8a8b7b0405ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mle_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_binary_cols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def encode_binary_cols(app_train, app_test):\n",
    "    # Create a label encoder object\n",
    "    le = LabelEncoder()\n",
    "    le_count = 0\n",
    "    encoded_cols = []\n",
    "    # Iterate through the columns\n",
    "    for col in app_train:\n",
    "        if app_train[col].dtype == 'object':\n",
    "            # If 2 or fewer unique categories (a nan will count as a category)\n",
    "            if len(list(app_train[col].unique())) <= 2:\n",
    "                # Train on the training data\n",
    "                le.fit(app_train[col])\n",
    "                # Transform both training and testing data\n",
    "                app_train[col] = le.transform(app_train[col])\n",
    "                app_test[col] = le.transform(app_test[col])\n",
    "                encoded_cols.append(col)\n",
    "\n",
    "                # Keep track of how many columns were label encoded\n",
    "                le_count += 1\n",
    "                \n",
    "train_data, test_data = encode_binary_cols(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE HOT ENCODED\n",
      "Training Features shape:  (307511, 244)\n",
      "Testing Features shape:  (48744, 240)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(app_train, app_test):\n",
    "    # one-hot encoding of categorical variables\n",
    "    # Dummy encoding will not create a column for nans\n",
    "    app_train = pd.get_dummies(app_train)\n",
    "    app_test = pd.get_dummies(app_test)\n",
    "\n",
    "    print(\"ONE HOT ENCODED\")\n",
    "    print('Training Features shape: ', app_train.shape)\n",
    "    print('Testing Features shape: ', app_test.shape)\n",
    "    return app_train, app_test\n",
    "\n",
    "train_data, test_data = one_hot_encode(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALIGNED:\n",
      "Training Features shape:  (307511, 241)\n",
      "Testing Features shape:  (48744, 240)\n"
     ]
    }
   ],
   "source": [
    "def align_data(app_train, app_test):\n",
    "    # ALIGN TEST AND TRAIN DATAFRAMES SO COLUMNS MATCH\n",
    "    train_labels = app_train['TARGET']\n",
    "\n",
    "    # Align the training and testing data, keep only columns present in both dataframes\n",
    "    app_train, app_test = app_train.align(app_test, join='inner', axis=1)\n",
    "\n",
    "    # Add the target back in\n",
    "    app_train['TARGET'] = train_labels\n",
    "\n",
    "    print(\"ALIGNED:\")\n",
    "    print('Training Features shape: ', app_train.shape)\n",
    "    print('Testing Features shape: ', app_test.shape)\n",
    "    return app_train, app_test, train_labels\n",
    "\n",
    "train_data, test_data, train_Y = align_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 0 anomalies in the test data out of 48744 entries\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_days_employed_anomaly(app_train, app_test):\n",
    "    # DEALING WITH ANOMALOUS DATA IN 'DAYS_EMPLOYED' COL\n",
    "\n",
    "    # Create an anomalous flag column\n",
    "    app_train['DAYS_EMPLOYED_ANOM'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "    # Replace the anomalous values with nan\n",
    "    app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "    app_train['DAYS_EMPLOYED'].plot.hist(title='Days Employment Histogram');\n",
    "    plt.xlabel('Days Employment');\n",
    "\n",
    "    app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "    app_test[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "    print('There were %d anomalies in the test data out of %d entries' % (\n",
    "        app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))\n",
    "    return app_train, app_test\n",
    "\n",
    "train_data, test_data = remove_days_employed_anomaly(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPUTED AND NORMALISED\n",
      "Training data shape:  (307511, 239)\n",
      "Testing data shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "def normalise_and_impute(app_train, app_test, impute_strategy='mean'):\n",
    "    # Drop the target from the training data\n",
    "    if 'TARGET' in app_train:\n",
    "        train = app_train.drop(columns=['TARGET'])\n",
    "    else:\n",
    "        train = app_train.copy()\n",
    "    train = train.drop(columns=['SK_ID_CURR'])  #\n",
    "\n",
    "    test = app_test.copy()\n",
    "    test = test.drop(columns=['SK_ID_CURR'])  #\n",
    "\n",
    "    # Feature names\n",
    "    features = list(train.columns)\n",
    "\n",
    "    # Median imputation of missing values\n",
    "    imputer = Imputer(strategy=impute_strategy)\n",
    "    # Fit on the training data\n",
    "    imputer.fit(train)\n",
    "    # Transform both training and testing data\n",
    "    train = imputer.transform(train)\n",
    "    test = imputer.transform(test)  ### test was app_test\n",
    "\n",
    "    # Normalise\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))  # Scale each feature to 0-1\n",
    "    scaler.fit(train)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    print(\"IMPUTED AND NORMALISED\")\n",
    "    print('Training data shape: ', train.shape)\n",
    "    print('Testing data shape: ', test.shape)\n",
    "    return train, test, features\n",
    "\n",
    "# train_X and test_X are np arrays\n",
    "# train_X, test_X, feature_names = normalise_and_impute(train_data, test_data, impute_strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_submission(app_test, predictions, save_path):\n",
    "    # Submission dataframe\n",
    "    submit = app_test[['SK_ID_CURR']]\n",
    "    submit['TARGET'] = predictions\n",
    "\n",
    "    # Save the submission to a csv file\n",
    "    submit.to_csv(save_path, index=False)\n",
    "    print(\"Predictions saved to: \", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_log_reg(train, train_Y, test, save_path):\n",
    "    # Make the model with the specified regularization parameter\n",
    "    log_reg = LogisticRegression(C=0.0001)\n",
    "\n",
    "    # Train on the training data\n",
    "    log_reg.fit(train, train_Y)\n",
    "\n",
    "    # Make predictions - only require 2nd columns (representing the probability that the target is 1)\n",
    "    log_reg_pred = log_reg.predict_proba(test)[:, 1]\n",
    "\n",
    "    # Save model\n",
    "    save_pickle(\"../models/log_reg_new.pickle\", log_reg)  # save model\n",
    "    print(\"Log reg baseline model saved to: \", save_path)\n",
    "    return log_reg, log_reg_pred\n",
    "\n",
    "# model, preds = baseline_log_reg(train_X, train_Y, test_X, save_path=\"../models/test.pickle\")\n",
    "# create_and_save_submission(test_data, preds, save_path='../test_predictions/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_log_reg(train, train_Y, test, save_path):\n",
    "    '''\n",
    "    Mean imputation\n",
    "    Best Penalty: l2\n",
    "    Best C: 1.668088018810296\n",
    "    test acc -> 0.73846\n",
    "    '''\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Search parameters and search space\n",
    "    penalty = ['l1', 'l2']\n",
    "    C = uniform(loc=0, scale=4)\n",
    "    hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "    # Create randomized search 5-fold cross validation and 100 iterations\n",
    "    clf = RandomizedSearchCV(model, hyperparameters, random_state=1, n_iter=5, cv=5, verbose=1)\n",
    "    # Fit randomized search\n",
    "    best_model = clf.fit(train, train_Y)\n",
    "\n",
    "    print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "    print('Best C:', best_model.best_estimator_.get_params()['C'])\n",
    "\n",
    "    predictions = best_model.predict_proba(test)[:, 1]\n",
    "\n",
    "    # Save model\n",
    "    save_pickle(\"../models/log_reg_new.pickle\", model)  # save model\n",
    "    print(\"Log reg baseline model saved to: \", save_path)\n",
    "\n",
    "    return model, predictions\n",
    "\n",
    "# model, preds = random_search_log_reg(train_X, train_Y, test_X, save_path=\"../models/test.pickle\")\n",
    "# create_and_save_submission(test_data, preds, save_path='../test_predictions/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPUTED AND NORMALISED\n",
      "Training data shape:  (307511, 239)\n",
      "Testing data shape:  (48744, 239)\n",
      "Run 0 AUC socre: 0.7455418539019963\n",
      "Run 1 AUC socre: 0.7482204392069075\n",
      "Run 2 AUC socre: 0.7434560943702402\n",
      "Run 3 AUC socre: 0.7437869495647487\n"
     ]
    }
   ],
   "source": [
    "def cross_val_roc_curve(train_X, train_Y, classifier):\n",
    "    # From https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html\n",
    "\n",
    "    # ROC AUC with stratified cross validation\n",
    "    X = train_X\n",
    "    y = train_Y\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=6, shuffle=True)\n",
    "    tprs = []  # true positive rate scores\n",
    "    aucs = []  # area under curve scores\n",
    "    mean_fpr = np.linspace(0, 1, 100)  # mean false positive rates\n",
    "\n",
    "    i = 0\n",
    "    # train and test for each fold\n",
    "    for train_sample, test_sample in cv.split(X, y):\n",
    "        probas_ = classifier.fit(X[train_sample], y[train_sample]).predict_proba(X[test_sample])\n",
    "        # Compute ROC curve and area the curve\n",
    "        fpr, tpr, thresholds = roc_curve(y[test_sample], probas_[:, 1])\n",
    "        tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "        tprs[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        print(\"Run {} AUC socre: {}\".format(i, roc_auc))\n",
    "\n",
    "        '''Everything below this point is just for the plot'''\n",
    "        plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "                 label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "        i += 1\n",
    "    # plot roc curve for fold\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "             label='Chance', alpha=.8)\n",
    "\n",
    "    # caluclate and plot mean auc\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "             label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "             lw=2, alpha=.8)\n",
    "\n",
    "    # plot standard deviation area\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                     label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    # add labels to plot\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    print(\"Avg ROC AUC score: {}\".format(np.mean(aucs)))\n",
    "\n",
    "# model = load_pickle(\"../models/log_reg_new.pickle\")\n",
    "# train_X, test_X, feature_names = normalise_and_impute(train_data, test_data, impute_strategy='mean')\n",
    "# cross_val_roc_curve(train_X, train_Y, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.274561\n",
      "         Iterations 7\n",
      "Selected Feature EXT_SOURCE_3\n",
      "AIC 168863.02936295504\n",
      "BIC 168873.66562909298\n"
     ]
    }
   ],
   "source": [
    "def feature_aic_bic(app_train, feature_name: str):\n",
    "    # calculates the aic and bic values between the target and a column\n",
    "    # http://www.differencebetween.net/miscellaneous/difference-between-aic-and-bic/\n",
    "\n",
    "    data = app_train.copy()\n",
    "    data = data[[feature_name, \"TARGET\"]]\n",
    "\n",
    "    # Median imputation of missing values\n",
    "    imputer = Imputer(strategy='mean')\n",
    "    imputer.fit(data)\n",
    "    imputed_data = imputer.transform(data)\n",
    "    data[feature_name] = imputed_data\n",
    "\n",
    "    data[\"intercept\"] = 1.0\n",
    "    logit = sm.Logit(data[\"TARGET\"], data[feature_name])\n",
    "    result = logit.fit()\n",
    "\n",
    "    # result.summary2() # uncomment for full summary\n",
    "    print(\"Selected Feature\", feature_name)\n",
    "    print(\"AIC\", result.aic)\n",
    "    print(\"BIC\", result.bic)\n",
    "\n",
    "    # 168863, 0.274561 - ext3 mean\n",
    "model = load_pickle(\"../models/log_reg_opt.pickle\")\n",
    "feature_aic_bic(train_data, \"EXT_SOURCE_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputed_col_aic(data, feature_name):\n",
    "#     data[\"intercept\"] = 1.0\n",
    "    logit = sm.Logit(data[\"TARGET\"], data[feature_name])\n",
    "    result = logit.fit()\n",
    "    print(\"AIC\", result.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_correlations(app_train, feature, n=15):\n",
    "    correlations = app_train.corr()[feature]\n",
    "    correlations = abs(correlations).sort_values().tail(\n",
    "        n)  # sort by correlation value (regardless if it's positive or negative)\n",
    "    correlations = correlations.dropna()  # drop nans\n",
    "    correlations = correlations.drop(labels=[feature, 'TARGET'])  # remove corr to itself and target\n",
    "    return correlations.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_corr_knn_imputation(top_corrs, feature: str, app_train, app_test):\n",
    "#     top_corrs = get_top_correlations(train_data, feature, n=10)  # TODO -> uncomment once working\n",
    "\n",
    "    # create training data from columns with values\n",
    "    not_null_mask = app_train[feature].notna()  # true if not nan = mask to get the values to train on\n",
    "    train_x = app_train[not_null_mask][\n",
    "        top_corrs]  # get all top corr cols (minus target) which have a ext_source_3 value\n",
    "    train_y = app_train[not_null_mask][[feature]]\n",
    "\n",
    "    # imputation of missing values for the other columns\n",
    "    imputer = Imputer(strategy='mean')\n",
    "    train_x = imputer.fit_transform(train_x)\n",
    "\n",
    "    # get the rows which require imputation\n",
    "    test_x = app_train[app_train[feature].isna()][top_corrs]  # only null values\n",
    "    imputer = Imputer(strategy='mean')\n",
    "    test_x = imputer.fit_transform(test_x)\n",
    "\n",
    "    # as above but for the app_test data\n",
    "    app_test_x = app_test[app_test[feature].isna()][top_corrs]  # only null values\n",
    "    imputer = Imputer(strategy='mean')\n",
    "    app_test_x = imputer.fit_transform(app_test_x)\n",
    "\n",
    "    # train and predict\n",
    "    neigh = KNeighborsRegressor(n_neighbors=150)\n",
    "    neigh.fit(train_x, train_y)\n",
    "    y_test = neigh.predict(test_x)\n",
    "    y_app_test = neigh.predict(app_test_x)\n",
    "\n",
    "    # get the column to update nulls\n",
    "    filled_col = app_train[[feature]]\n",
    "    filled_col[filled_col[feature].isna()] = y_test\n",
    "    # fill column\n",
    "    data = app_train.copy()\n",
    "    data[feature] = filled_col\n",
    "\n",
    "    # get the column to update nulls for app_test\n",
    "    filled_col_app_test = app_test[[feature]]\n",
    "    filled_col_app_test[filled_col_app_test[feature].isna()] = y_app_test\n",
    "    # fill column\n",
    "    data_app_test = app_test.copy()\n",
    "    data_app_test[feature] = filled_col_app_test\n",
    "\n",
    "    imputed_col_aic(data, feature)\n",
    "    return data, data_app_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corrs = get_top_correlations(train_data, 'EXT_SOURCE_3', n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.273478\n",
      "         Iterations 7\n",
      "AIC 168196.7461043481\n",
      "IMPUTED AND NORMALISED\n",
      "Training data shape:  (307511, 239)\n",
      "Testing data shape:  (48744, 239)\n",
      "File saved at  ../models/log_reg_new.pickle\n",
      "Log reg baseline model saved to:  ../models/test.pickle\n",
      "Predictions saved to:  ../test_predictions/test.csv\n"
     ]
    }
   ],
   "source": [
    "def log_reg_knn_imputation(top_corrs, feat_name, app_train, app_test, model_save_path, predications_save_path):\n",
    "#     top_corrs = get_top_correlations(train_data, 'EXT_SOURCE_3', n=15)\n",
    "    train_Y = app_train['TARGET']\n",
    "    train_X, test_X = top_corr_knn_imputation(top_corrs, feat_name, app_train, app_test)\n",
    "    train_X, test_X, feat_names = normalise_and_impute(train_X, test_X,\n",
    "                                                       impute_strategy='mean')\n",
    "\n",
    "    model, preds = baseline_log_reg(train_X, train_Y, test_X, save_path=model_save_path)\n",
    "    create_and_save_submission(test_data, preds, save_path=predications_save_path)\n",
    "\n",
    "    \n",
    "log_reg_knn_imputation(top_corrs, 'EXT_SOURCE_3', train_data, test_data,\n",
    "                       model_save_path=\"../models/test.pickle\",\n",
    "                       predications_save_path='../test_predictions/test.csv') \n",
    "# test score -> 0.67843 (using baseline params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
